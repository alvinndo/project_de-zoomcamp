[2022-04-25 05:59:36,956] {taskinstance.py:1043} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2015-01-01T00:00:00+00:00 [queued]>
[2022-04-25 05:59:37,008] {taskinstance.py:1043} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2015-01-01T00:00:00+00:00 [queued]>
[2022-04-25 05:59:37,010] {taskinstance.py:1249} INFO - 
--------------------------------------------------------------------------------
[2022-04-25 05:59:37,013] {taskinstance.py:1250} INFO - Starting attempt 1 of 2
[2022-04-25 05:59:37,015] {taskinstance.py:1251} INFO - 
--------------------------------------------------------------------------------
[2022-04-25 05:59:37,080] {taskinstance.py:1270} INFO - Executing <Task(BashOperator): download_dataset_task> on 2015-01-01 00:00:00+00:00
[2022-04-25 05:59:37,093] {standard_task_runner.py:52} INFO - Started process 1036 to run task
[2022-04-25 05:59:37,113] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcp_dag', 'download_dataset_task', 'scheduled__2015-01-01T00:00:00+00:00', '--job-id', '304', '--raw', '--subdir', 'DAGS_FOLDER/ingest_to_gcs_dag.py', '--cfg-path', '/tmp/tmpq02sftic', '--error-file', '/tmp/tmpacokyity']
[2022-04-25 05:59:37,116] {standard_task_runner.py:80} INFO - Job 304: Subtask download_dataset_task
[2022-04-25 05:59:37,629] {logging_mixin.py:109} INFO - Running <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2015-01-01T00:00:00+00:00 [running]> on host d74937eb3452
[2022-04-25 05:59:37,930] {logging_mixin.py:109} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:156 AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
[2022-04-25 05:59:38,187] {taskinstance.py:1448} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=data_ingestion_gcp_dag
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2015-01-01T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2015-01-01T00:00:00+00:00
[2022-04-25 05:59:38,195] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-04-25 05:59:38,197] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://www.bls.gov/lau/laucnty15.xlsx > /opt/***//laucnty15.xlsx']
[2022-04-25 05:59:38,212] {subprocess.py:85} INFO - Output:
[2022-04-25 05:59:38,622] {subprocess.py:93} INFO - Command exited with return code 0
[2022-04-25 05:59:38,861] {taskinstance.py:1288} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcp_dag, task_id=download_dataset_task, execution_date=20150101T000000, start_date=20220425T055936, end_date=20220425T055938
[2022-04-25 05:59:38,931] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-04-25 05:59:39,164] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-04-28 06:11:48,788] {taskinstance.py:1043} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2015-01-01T00:00:00+00:00 [queued]>
[2022-04-28 06:11:48,841] {taskinstance.py:1043} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2015-01-01T00:00:00+00:00 [queued]>
[2022-04-28 06:11:48,843] {taskinstance.py:1249} INFO - 
--------------------------------------------------------------------------------
[2022-04-28 06:11:48,845] {taskinstance.py:1250} INFO - Starting attempt 1 of 2
[2022-04-28 06:11:48,846] {taskinstance.py:1251} INFO - 
--------------------------------------------------------------------------------
[2022-04-28 06:11:48,897] {taskinstance.py:1270} INFO - Executing <Task(BashOperator): download_dataset_task> on 2015-01-01 00:00:00+00:00
[2022-04-28 06:11:48,907] {standard_task_runner.py:52} INFO - Started process 2913 to run task
[2022-04-28 06:11:48,917] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcp_dag', 'download_dataset_task', 'scheduled__2015-01-01T00:00:00+00:00', '--job-id', '589', '--raw', '--subdir', 'DAGS_FOLDER/ingest_to_gcs_dag.py', '--cfg-path', '/tmp/tmphwm360fo', '--error-file', '/tmp/tmpmjfx4mj8']
[2022-04-28 06:11:48,921] {standard_task_runner.py:80} INFO - Job 589: Subtask download_dataset_task
[2022-04-28 06:11:49,327] {logging_mixin.py:109} INFO - Running <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2015-01-01T00:00:00+00:00 [running]> on host d4721d223bdd
[2022-04-28 06:11:49,581] {logging_mixin.py:109} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:156 AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
[2022-04-28 06:11:49,764] {taskinstance.py:1448} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=data_ingestion_gcp_dag
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2015-01-01T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2015-01-01T00:00:00+00:00
[2022-04-28 06:11:49,769] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-04-28 06:11:49,772] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://www.bls.gov/lau/laucnty15.xlsx > /opt/***/laucnty15.xlsx']
[2022-04-28 06:11:49,789] {subprocess.py:85} INFO - Output:
[2022-04-28 06:11:50,619] {subprocess.py:93} INFO - Command exited with return code 0
[2022-04-28 06:11:50,909] {taskinstance.py:1288} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcp_dag, task_id=download_dataset_task, execution_date=20150101T000000, start_date=20220428T061148, end_date=20220428T061150
[2022-04-28 06:11:50,984] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-04-28 06:11:51,644] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-04-29 02:39:26,862] {taskinstance.py:1043} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2015-01-01T00:00:00+00:00 [queued]>
[2022-04-29 02:39:26,918] {taskinstance.py:1043} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2015-01-01T00:00:00+00:00 [queued]>
[2022-04-29 02:39:26,920] {taskinstance.py:1249} INFO - 
--------------------------------------------------------------------------------
[2022-04-29 02:39:26,922] {taskinstance.py:1250} INFO - Starting attempt 1 of 2
[2022-04-29 02:39:26,924] {taskinstance.py:1251} INFO - 
--------------------------------------------------------------------------------
[2022-04-29 02:39:26,981] {taskinstance.py:1270} INFO - Executing <Task(BashOperator): download_dataset_task> on 2015-01-01 00:00:00+00:00
[2022-04-29 02:39:26,991] {standard_task_runner.py:52} INFO - Started process 6276 to run task
[2022-04-29 02:39:27,009] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcp_dag', 'download_dataset_task', 'scheduled__2015-01-01T00:00:00+00:00', '--job-id', '763', '--raw', '--subdir', 'DAGS_FOLDER/ingest_to_gcs_dag.py', '--cfg-path', '/tmp/tmpq4rythxo', '--error-file', '/tmp/tmphrm2x4i8']
[2022-04-29 02:39:27,012] {standard_task_runner.py:80} INFO - Job 763: Subtask download_dataset_task
[2022-04-29 02:39:27,427] {logging_mixin.py:109} INFO - Running <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2015-01-01T00:00:00+00:00 [running]> on host 6fd0ba274d58
[2022-04-29 02:39:27,856] {logging_mixin.py:109} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:156 AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
[2022-04-29 02:39:28,166] {taskinstance.py:1448} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=data_ingestion_gcp_dag
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2015-01-01T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2015-01-01T00:00:00+00:00
[2022-04-29 02:39:28,173] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-04-29 02:39:28,176] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://www.bls.gov/lau/laucnty15.xlsx > /opt/***/laucnty15.xlsx']
[2022-04-29 02:39:28,219] {subprocess.py:85} INFO - Output:
[2022-04-29 02:39:29,281] {subprocess.py:93} INFO - Command exited with return code 0
[2022-04-29 02:39:29,510] {taskinstance.py:1288} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcp_dag, task_id=download_dataset_task, execution_date=20150101T000000, start_date=20220429T023926, end_date=20220429T023929
[2022-04-29 02:39:29,593] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-04-29 02:39:30,104] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-05-02 07:57:25,917] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2015-01-01T00:00:00+00:00 [queued]>
[2022-05-02 07:57:25,959] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2015-01-01T00:00:00+00:00 [queued]>
[2022-05-02 07:57:25,961] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-05-02 07:57:25,962] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-05-02 07:57:25,963] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-05-02 07:57:26,012] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2015-01-01 00:00:00+00:00
[2022-05-02 07:57:26,021] {standard_task_runner.py:52} INFO - Started process 9898 to run task
[2022-05-02 07:57:26,028] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcp_dag', 'download_dataset_task', 'scheduled__2015-01-01T00:00:00+00:00', '--job-id', '894', '--raw', '--subdir', 'DAGS_FOLDER/ingest_to_gcs_dag.py', '--cfg-path', '/tmp/tmp6lqv_kk2', '--error-file', '/tmp/tmpg1bdkxfc']
[2022-05-02 07:57:26,031] {standard_task_runner.py:77} INFO - Job 894: Subtask download_dataset_task
[2022-05-02 07:57:26,412] {logging_mixin.py:109} INFO - Running <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2015-01-01T00:00:00+00:00 [running]> on host ae42322ae538
[2022-05-02 07:57:26,672] {logging_mixin.py:109} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152 AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
[2022-05-02 07:57:26,854] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=data_ingestion_gcp_dag
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2015-01-01T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2015-01-01T00:00:00+00:00
[2022-05-02 07:57:26,858] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-05-02 07:57:26,860] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://www.bls.gov/lau/laucnty15.xlsx > /opt/***/laucnty15.xlsx']
[2022-05-02 07:57:26,875] {subprocess.py:85} INFO - Output:
[2022-05-02 07:57:27,223] {subprocess.py:93} INFO - Command exited with return code 0
[2022-05-02 07:57:27,414] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcp_dag, task_id=download_dataset_task, execution_date=20150101T000000, start_date=20220502T075725, end_date=20220502T075727
[2022-05-02 07:57:27,486] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-05-02 07:57:27,735] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-05-02 09:19:39,380] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2015-01-01T00:00:00+00:00 [queued]>
[2022-05-02 09:19:39,425] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2015-01-01T00:00:00+00:00 [queued]>
[2022-05-02 09:19:39,427] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-05-02 09:19:39,429] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-05-02 09:19:39,430] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-05-02 09:19:39,476] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2015-01-01 00:00:00+00:00
[2022-05-02 09:19:39,485] {standard_task_runner.py:52} INFO - Started process 3220 to run task
[2022-05-02 09:19:39,495] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcp_dag', 'download_dataset_task', 'scheduled__2015-01-01T00:00:00+00:00', '--job-id', '1015', '--raw', '--subdir', 'DAGS_FOLDER/ingest_to_gcs_dag.py', '--cfg-path', '/tmp/tmpxtss1_mp', '--error-file', '/tmp/tmp78r2edvu']
[2022-05-02 09:19:39,498] {standard_task_runner.py:77} INFO - Job 1015: Subtask download_dataset_task
[2022-05-02 09:19:39,901] {logging_mixin.py:109} INFO - Running <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2015-01-01T00:00:00+00:00 [running]> on host 98c324cf1bb6
[2022-05-02 09:19:40,156] {logging_mixin.py:109} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152 AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
[2022-05-02 09:19:40,335] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=data_ingestion_gcp_dag
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2015-01-01T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2015-01-01T00:00:00+00:00
[2022-05-02 09:19:40,339] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-05-02 09:19:40,341] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://www.bls.gov/lau/laucnty15.xlsx > /opt/***/laucnty15.xlsx']
[2022-05-02 09:19:40,356] {subprocess.py:85} INFO - Output:
[2022-05-02 09:19:40,708] {subprocess.py:93} INFO - Command exited with return code 0
[2022-05-02 09:19:40,915] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcp_dag, task_id=download_dataset_task, execution_date=20150101T000000, start_date=20220502T091939, end_date=20220502T091940
[2022-05-02 09:19:40,997] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-05-02 09:19:41,290] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-05-02 16:00:42,604] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2015-01-01T00:00:00+00:00 [queued]>
[2022-05-02 16:00:42,648] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2015-01-01T00:00:00+00:00 [queued]>
[2022-05-02 16:00:42,650] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-05-02 16:00:42,651] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-05-02 16:00:42,652] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-05-02 16:00:42,701] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2015-01-01 00:00:00+00:00
[2022-05-02 16:00:42,710] {standard_task_runner.py:52} INFO - Started process 2356 to run task
[2022-05-02 16:00:42,726] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcp_dag', 'download_dataset_task', 'scheduled__2015-01-01T00:00:00+00:00', '--job-id', '1116', '--raw', '--subdir', 'DAGS_FOLDER/ingest_to_gcs_dag.py', '--cfg-path', '/tmp/tmpqvdmplau', '--error-file', '/tmp/tmpgq71_f3d']
[2022-05-02 16:00:42,729] {standard_task_runner.py:77} INFO - Job 1116: Subtask download_dataset_task
[2022-05-02 16:00:43,123] {logging_mixin.py:109} INFO - Running <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2015-01-01T00:00:00+00:00 [running]> on host 9f5021834e17
[2022-05-02 16:00:43,386] {logging_mixin.py:109} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152 AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
[2022-05-02 16:00:43,584] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=data_ingestion_gcp_dag
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2015-01-01T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2015-01-01T00:00:00+00:00
[2022-05-02 16:00:43,590] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-05-02 16:00:43,592] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://www.bls.gov/lau/laucnty15.xlsx > /opt/***/laucnty15.xlsx']
[2022-05-02 16:00:43,611] {subprocess.py:85} INFO - Output:
[2022-05-02 16:00:44,114] {subprocess.py:93} INFO - Command exited with return code 0
[2022-05-02 16:00:44,534] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcp_dag, task_id=download_dataset_task, execution_date=20150101T000000, start_date=20220502T160042, end_date=20220502T160044
[2022-05-02 16:00:44,627] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-05-02 16:00:45,073] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-05-02 16:35:50,978] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2015-01-01T00:00:00+00:00 [queued]>
[2022-05-02 16:35:51,033] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2015-01-01T00:00:00+00:00 [queued]>
[2022-05-02 16:35:51,037] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-05-02 16:35:51,040] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-05-02 16:35:51,043] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-05-02 16:35:51,115] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2015-01-01 00:00:00+00:00
[2022-05-02 16:35:51,128] {standard_task_runner.py:52} INFO - Started process 6950 to run task
[2022-05-02 16:35:51,145] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcp_dag', 'download_dataset_task', 'scheduled__2015-01-01T00:00:00+00:00', '--job-id', '1223', '--raw', '--subdir', 'DAGS_FOLDER/ingest_to_gcs_dag.py', '--cfg-path', '/tmp/tmp4i99zyq0', '--error-file', '/tmp/tmpk34kv9pi']
[2022-05-02 16:35:51,148] {standard_task_runner.py:77} INFO - Job 1223: Subtask download_dataset_task
[2022-05-02 16:35:51,944] {logging_mixin.py:109} INFO - Running <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2015-01-01T00:00:00+00:00 [running]> on host 9f5021834e17
[2022-05-02 16:35:52,419] {logging_mixin.py:109} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152 AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
[2022-05-02 16:35:52,875] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=data_ingestion_gcp_dag
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2015-01-01T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2015-01-01T00:00:00+00:00
[2022-05-02 16:35:52,882] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-05-02 16:35:52,886] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://www.bls.gov/lau/laucnty15.xlsx > /opt/***/laucnty15.xlsx']
[2022-05-02 16:35:52,937] {subprocess.py:85} INFO - Output:
[2022-05-02 16:35:53,542] {subprocess.py:93} INFO - Command exited with return code 0
[2022-05-02 16:35:53,900] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcp_dag, task_id=download_dataset_task, execution_date=20150101T000000, start_date=20220502T163550, end_date=20220502T163553
[2022-05-02 16:35:54,006] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-05-02 16:35:54,333] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-05-02 16:51:07,129] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2015-01-01T00:00:00+00:00 [queued]>
[2022-05-02 16:51:07,171] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2015-01-01T00:00:00+00:00 [queued]>
[2022-05-02 16:51:07,173] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-05-02 16:51:07,174] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-05-02 16:51:07,175] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-05-02 16:51:07,219] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2015-01-01 00:00:00+00:00
[2022-05-02 16:51:07,228] {standard_task_runner.py:52} INFO - Started process 9688 to run task
[2022-05-02 16:51:07,237] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcp_dag', 'download_dataset_task', 'scheduled__2015-01-01T00:00:00+00:00', '--job-id', '1325', '--raw', '--subdir', 'DAGS_FOLDER/ingest_to_gcs_dag.py', '--cfg-path', '/tmp/tmpsrus6o0g', '--error-file', '/tmp/tmptsl_lf54']
[2022-05-02 16:51:07,240] {standard_task_runner.py:77} INFO - Job 1325: Subtask download_dataset_task
[2022-05-02 16:51:07,629] {logging_mixin.py:109} INFO - Running <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2015-01-01T00:00:00+00:00 [running]> on host 9f5021834e17
[2022-05-02 16:51:07,882] {logging_mixin.py:109} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152 AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
[2022-05-02 16:51:08,070] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=data_ingestion_gcp_dag
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2015-01-01T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2015-01-01T00:00:00+00:00
[2022-05-02 16:51:08,075] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-05-02 16:51:08,077] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://www.bls.gov/lau/laucnty15.xlsx > /opt/***/laucnty15.xlsx']
[2022-05-02 16:51:08,095] {subprocess.py:85} INFO - Output:
[2022-05-02 16:51:08,706] {subprocess.py:93} INFO - Command exited with return code 0
[2022-05-02 16:51:09,073] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcp_dag, task_id=download_dataset_task, execution_date=20150101T000000, start_date=20220502T165107, end_date=20220502T165109
[2022-05-02 16:51:09,138] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-05-02 16:51:09,442] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
