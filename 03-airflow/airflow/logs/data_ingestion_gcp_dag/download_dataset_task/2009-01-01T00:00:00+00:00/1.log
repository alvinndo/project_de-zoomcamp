[2022-04-25 05:59:23,818] {taskinstance.py:1043} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2009-01-01T00:00:00+00:00 [queued]>
[2022-04-25 05:59:23,881] {taskinstance.py:1043} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2009-01-01T00:00:00+00:00 [queued]>
[2022-04-25 05:59:23,885] {taskinstance.py:1249} INFO - 
--------------------------------------------------------------------------------
[2022-04-25 05:59:23,888] {taskinstance.py:1250} INFO - Starting attempt 1 of 2
[2022-04-25 05:59:23,891] {taskinstance.py:1251} INFO - 
--------------------------------------------------------------------------------
[2022-04-25 05:59:23,954] {taskinstance.py:1270} INFO - Executing <Task(BashOperator): download_dataset_task> on 2009-01-01 00:00:00+00:00
[2022-04-25 05:59:23,965] {standard_task_runner.py:52} INFO - Started process 927 to run task
[2022-04-25 05:59:23,986] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcp_dag', 'download_dataset_task', 'scheduled__2009-01-01T00:00:00+00:00', '--job-id', '298', '--raw', '--subdir', 'DAGS_FOLDER/ingest_to_gcs_dag.py', '--cfg-path', '/tmp/tmpn33qm1sh', '--error-file', '/tmp/tmpxp5m6g6h']
[2022-04-25 05:59:23,989] {standard_task_runner.py:80} INFO - Job 298: Subtask download_dataset_task
[2022-04-25 05:59:24,462] {logging_mixin.py:109} INFO - Running <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2009-01-01T00:00:00+00:00 [running]> on host d74937eb3452
[2022-04-25 05:59:24,790] {logging_mixin.py:109} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:156 AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
[2022-04-25 05:59:24,981] {taskinstance.py:1448} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=data_ingestion_gcp_dag
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2009-01-01T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2009-01-01T00:00:00+00:00
[2022-04-25 05:59:24,986] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-04-25 05:59:24,990] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://www.bls.gov/lau/laucnty09.xlsx > /opt/***//laucnty09.xlsx']
[2022-04-25 05:59:25,022] {subprocess.py:85} INFO - Output:
[2022-04-25 05:59:25,488] {subprocess.py:93} INFO - Command exited with return code 0
[2022-04-25 05:59:25,703] {taskinstance.py:1288} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcp_dag, task_id=download_dataset_task, execution_date=20090101T000000, start_date=20220425T055923, end_date=20220425T055925
[2022-04-25 05:59:25,756] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-04-25 05:59:26,064] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-04-28 06:08:20,838] {taskinstance.py:1043} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2009-01-01T00:00:00+00:00 [queued]>
[2022-04-28 06:08:20,880] {taskinstance.py:1043} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2009-01-01T00:00:00+00:00 [queued]>
[2022-04-28 06:08:20,882] {taskinstance.py:1249} INFO - 
--------------------------------------------------------------------------------
[2022-04-28 06:08:20,883] {taskinstance.py:1250} INFO - Starting attempt 1 of 2
[2022-04-28 06:08:20,884] {taskinstance.py:1251} INFO - 
--------------------------------------------------------------------------------
[2022-04-28 06:08:20,932] {taskinstance.py:1270} INFO - Executing <Task(BashOperator): download_dataset_task> on 2009-01-01 00:00:00+00:00
[2022-04-28 06:08:20,941] {standard_task_runner.py:52} INFO - Started process 2353 to run task
[2022-04-28 06:08:20,949] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcp_dag', 'download_dataset_task', 'scheduled__2009-01-01T00:00:00+00:00', '--job-id', '562', '--raw', '--subdir', 'DAGS_FOLDER/ingest_to_gcs_dag.py', '--cfg-path', '/tmp/tmparcjecus', '--error-file', '/tmp/tmpik_pxh9x']
[2022-04-28 06:08:20,954] {standard_task_runner.py:80} INFO - Job 562: Subtask download_dataset_task
[2022-04-28 06:08:21,313] {logging_mixin.py:109} INFO - Running <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2009-01-01T00:00:00+00:00 [running]> on host d4721d223bdd
[2022-04-28 06:08:21,558] {logging_mixin.py:109} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:156 AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
[2022-04-28 06:08:21,757] {taskinstance.py:1448} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=data_ingestion_gcp_dag
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2009-01-01T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2009-01-01T00:00:00+00:00
[2022-04-28 06:08:21,763] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-04-28 06:08:21,765] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://www.bls.gov/lau/laucnty09.xlsx > /opt/***/laucnty09.xlsx']
[2022-04-28 06:08:21,783] {subprocess.py:85} INFO - Output:
[2022-04-28 06:08:22,468] {subprocess.py:93} INFO - Command exited with return code 0
[2022-04-28 06:08:22,661] {taskinstance.py:1288} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcp_dag, task_id=download_dataset_task, execution_date=20090101T000000, start_date=20220428T060820, end_date=20220428T060822
[2022-04-28 06:08:22,719] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-04-28 06:08:22,974] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-04-29 02:38:02,582] {taskinstance.py:1043} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2009-01-01T00:00:00+00:00 [queued]>
[2022-04-29 02:38:02,633] {taskinstance.py:1043} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2009-01-01T00:00:00+00:00 [queued]>
[2022-04-29 02:38:02,634] {taskinstance.py:1249} INFO - 
--------------------------------------------------------------------------------
[2022-04-29 02:38:02,636] {taskinstance.py:1250} INFO - Starting attempt 1 of 2
[2022-04-29 02:38:02,637] {taskinstance.py:1251} INFO - 
--------------------------------------------------------------------------------
[2022-04-29 02:38:02,697] {taskinstance.py:1270} INFO - Executing <Task(BashOperator): download_dataset_task> on 2009-01-01 00:00:00+00:00
[2022-04-29 02:38:02,713] {standard_task_runner.py:52} INFO - Started process 5894 to run task
[2022-04-29 02:38:02,730] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcp_dag', 'download_dataset_task', 'scheduled__2009-01-01T00:00:00+00:00', '--job-id', '739', '--raw', '--subdir', 'DAGS_FOLDER/ingest_to_gcs_dag.py', '--cfg-path', '/tmp/tmpnb4quxlo', '--error-file', '/tmp/tmprgp9zf8d']
[2022-04-29 02:38:02,734] {standard_task_runner.py:80} INFO - Job 739: Subtask download_dataset_task
[2022-04-29 02:38:03,121] {logging_mixin.py:109} INFO - Running <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2009-01-01T00:00:00+00:00 [running]> on host 6fd0ba274d58
[2022-04-29 02:38:03,398] {logging_mixin.py:109} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:156 AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
[2022-04-29 02:38:03,615] {taskinstance.py:1448} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=data_ingestion_gcp_dag
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2009-01-01T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2009-01-01T00:00:00+00:00
[2022-04-29 02:38:03,623] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-04-29 02:38:03,626] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://www.bls.gov/lau/laucnty09.xlsx > /opt/***/laucnty09.xlsx']
[2022-04-29 02:38:03,648] {subprocess.py:85} INFO - Output:
[2022-04-29 02:38:04,356] {subprocess.py:93} INFO - Command exited with return code 0
[2022-04-29 02:38:04,582] {taskinstance.py:1288} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcp_dag, task_id=download_dataset_task, execution_date=20090101T000000, start_date=20220429T023802, end_date=20220429T023804
[2022-04-29 02:38:04,679] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-04-29 02:38:04,954] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-05-02 07:56:29,012] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2009-01-01T00:00:00+00:00 [queued]>
[2022-05-02 07:56:29,055] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2009-01-01T00:00:00+00:00 [queued]>
[2022-05-02 07:56:29,057] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-05-02 07:56:29,058] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-05-02 07:56:29,059] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-05-02 07:56:29,098] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2009-01-01 00:00:00+00:00
[2022-05-02 07:56:29,118] {standard_task_runner.py:52} INFO - Started process 9628 to run task
[2022-05-02 07:56:29,120] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcp_dag', 'download_dataset_task', 'scheduled__2009-01-01T00:00:00+00:00', '--job-id', '877', '--raw', '--subdir', 'DAGS_FOLDER/ingest_to_gcs_dag.py', '--cfg-path', '/tmp/tmpqzlu6azz', '--error-file', '/tmp/tmpjqcao0pz']
[2022-05-02 07:56:29,127] {standard_task_runner.py:77} INFO - Job 877: Subtask download_dataset_task
[2022-05-02 07:56:29,493] {logging_mixin.py:109} INFO - Running <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2009-01-01T00:00:00+00:00 [running]> on host ae42322ae538
[2022-05-02 07:56:29,735] {logging_mixin.py:109} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152 AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
[2022-05-02 07:56:29,913] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=data_ingestion_gcp_dag
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2009-01-01T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2009-01-01T00:00:00+00:00
[2022-05-02 07:56:29,918] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-05-02 07:56:29,920] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://www.bls.gov/lau/laucnty09.xlsx > /opt/***/laucnty09.xlsx']
[2022-05-02 07:56:29,935] {subprocess.py:85} INFO - Output:
[2022-05-02 07:56:30,267] {subprocess.py:93} INFO - Command exited with return code 0
[2022-05-02 07:56:30,461] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcp_dag, task_id=download_dataset_task, execution_date=20090101T000000, start_date=20220502T075629, end_date=20220502T075630
[2022-05-02 07:56:30,555] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-05-02 07:56:30,929] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-05-02 09:18:34,548] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2009-01-01T00:00:00+00:00 [queued]>
[2022-05-02 09:18:34,592] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2009-01-01T00:00:00+00:00 [queued]>
[2022-05-02 09:18:34,593] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-05-02 09:18:34,594] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-05-02 09:18:34,595] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-05-02 09:18:34,640] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2009-01-01 00:00:00+00:00
[2022-05-02 09:18:34,650] {standard_task_runner.py:52} INFO - Started process 2915 to run task
[2022-05-02 09:18:34,658] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcp_dag', 'download_dataset_task', 'scheduled__2009-01-01T00:00:00+00:00', '--job-id', '997', '--raw', '--subdir', 'DAGS_FOLDER/ingest_to_gcs_dag.py', '--cfg-path', '/tmp/tmphd_wt4yi', '--error-file', '/tmp/tmpd54dw8pv']
[2022-05-02 09:18:34,661] {standard_task_runner.py:77} INFO - Job 997: Subtask download_dataset_task
[2022-05-02 09:18:35,039] {logging_mixin.py:109} INFO - Running <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2009-01-01T00:00:00+00:00 [running]> on host 98c324cf1bb6
[2022-05-02 09:18:35,297] {logging_mixin.py:109} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152 AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
[2022-05-02 09:18:35,475] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=data_ingestion_gcp_dag
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2009-01-01T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2009-01-01T00:00:00+00:00
[2022-05-02 09:18:35,480] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-05-02 09:18:35,482] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://www.bls.gov/lau/laucnty09.xlsx > /opt/***/laucnty09.xlsx']
[2022-05-02 09:18:35,498] {subprocess.py:85} INFO - Output:
[2022-05-02 09:18:35,843] {subprocess.py:93} INFO - Command exited with return code 0
[2022-05-02 09:18:36,046] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcp_dag, task_id=download_dataset_task, execution_date=20090101T000000, start_date=20220502T091834, end_date=20220502T091836
[2022-05-02 09:18:36,115] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-05-02 09:18:36,579] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-05-02 15:59:40,424] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2009-01-01T00:00:00+00:00 [queued]>
[2022-05-02 15:59:40,471] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2009-01-01T00:00:00+00:00 [queued]>
[2022-05-02 15:59:40,474] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-05-02 15:59:40,475] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-05-02 15:59:40,477] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-05-02 15:59:40,525] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2009-01-01 00:00:00+00:00
[2022-05-02 15:59:40,535] {standard_task_runner.py:52} INFO - Started process 2056 to run task
[2022-05-02 15:59:40,548] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcp_dag', 'download_dataset_task', 'scheduled__2009-01-01T00:00:00+00:00', '--job-id', '1098', '--raw', '--subdir', 'DAGS_FOLDER/ingest_to_gcs_dag.py', '--cfg-path', '/tmp/tmp9_8zd5pi', '--error-file', '/tmp/tmposyd8fjp']
[2022-05-02 15:59:40,552] {standard_task_runner.py:77} INFO - Job 1098: Subtask download_dataset_task
[2022-05-02 15:59:41,038] {logging_mixin.py:109} INFO - Running <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2009-01-01T00:00:00+00:00 [running]> on host 9f5021834e17
[2022-05-02 15:59:41,383] {logging_mixin.py:109} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152 AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
[2022-05-02 15:59:41,576] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=data_ingestion_gcp_dag
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2009-01-01T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2009-01-01T00:00:00+00:00
[2022-05-02 15:59:41,581] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-05-02 15:59:41,584] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://www.bls.gov/lau/laucnty09.xlsx > /opt/***/laucnty09.xlsx']
[2022-05-02 15:59:41,602] {subprocess.py:85} INFO - Output:
[2022-05-02 15:59:41,984] {subprocess.py:93} INFO - Command exited with return code 0
[2022-05-02 15:59:42,195] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcp_dag, task_id=download_dataset_task, execution_date=20090101T000000, start_date=20220502T155940, end_date=20220502T155942
[2022-05-02 15:59:42,322] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-05-02 15:59:42,707] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-05-02 16:34:39,762] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2009-01-01T00:00:00+00:00 [queued]>
[2022-05-02 16:34:39,824] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2009-01-01T00:00:00+00:00 [queued]>
[2022-05-02 16:34:39,827] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-05-02 16:34:39,830] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-05-02 16:34:39,832] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-05-02 16:34:39,893] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2009-01-01 00:00:00+00:00
[2022-05-02 16:34:39,907] {standard_task_runner.py:52} INFO - Started process 6623 to run task
[2022-05-02 16:34:39,931] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcp_dag', 'download_dataset_task', 'scheduled__2009-01-01T00:00:00+00:00', '--job-id', '1205', '--raw', '--subdir', 'DAGS_FOLDER/ingest_to_gcs_dag.py', '--cfg-path', '/tmp/tmp4agvchkn', '--error-file', '/tmp/tmpteeej5a4']
[2022-05-02 16:34:39,935] {standard_task_runner.py:77} INFO - Job 1205: Subtask download_dataset_task
[2022-05-02 16:34:40,390] {logging_mixin.py:109} INFO - Running <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2009-01-01T00:00:00+00:00 [running]> on host 9f5021834e17
[2022-05-02 16:34:40,799] {logging_mixin.py:109} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152 AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
[2022-05-02 16:34:41,173] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=data_ingestion_gcp_dag
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2009-01-01T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2009-01-01T00:00:00+00:00
[2022-05-02 16:34:41,182] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-05-02 16:34:41,187] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://www.bls.gov/lau/laucnty09.xlsx > /opt/***/laucnty09.xlsx']
[2022-05-02 16:34:41,222] {subprocess.py:85} INFO - Output:
[2022-05-02 16:34:41,873] {subprocess.py:93} INFO - Command exited with return code 0
[2022-05-02 16:34:42,120] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcp_dag, task_id=download_dataset_task, execution_date=20090101T000000, start_date=20220502T163439, end_date=20220502T163442
[2022-05-02 16:34:42,221] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-05-02 16:34:42,782] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-05-02 16:50:08,390] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2009-01-01T00:00:00+00:00 [queued]>
[2022-05-02 16:50:08,435] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2009-01-01T00:00:00+00:00 [queued]>
[2022-05-02 16:50:08,437] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-05-02 16:50:08,439] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-05-02 16:50:08,440] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-05-02 16:50:08,488] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2009-01-01 00:00:00+00:00
[2022-05-02 16:50:08,499] {standard_task_runner.py:52} INFO - Started process 9416 to run task
[2022-05-02 16:50:08,514] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcp_dag', 'download_dataset_task', 'scheduled__2009-01-01T00:00:00+00:00', '--job-id', '1309', '--raw', '--subdir', 'DAGS_FOLDER/ingest_to_gcs_dag.py', '--cfg-path', '/tmp/tmpq3900v4_', '--error-file', '/tmp/tmp_cu4xpxj']
[2022-05-02 16:50:08,517] {standard_task_runner.py:77} INFO - Job 1309: Subtask download_dataset_task
[2022-05-02 16:50:08,973] {logging_mixin.py:109} INFO - Running <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2009-01-01T00:00:00+00:00 [running]> on host 9f5021834e17
[2022-05-02 16:50:09,228] {logging_mixin.py:109} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152 AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
[2022-05-02 16:50:09,415] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=data_ingestion_gcp_dag
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2009-01-01T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2009-01-01T00:00:00+00:00
[2022-05-02 16:50:09,420] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-05-02 16:50:09,422] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://www.bls.gov/lau/laucnty09.xlsx > /opt/***/laucnty09.xlsx']
[2022-05-02 16:50:09,443] {subprocess.py:85} INFO - Output:
[2022-05-02 16:50:09,816] {subprocess.py:93} INFO - Command exited with return code 0
[2022-05-02 16:50:10,093] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcp_dag, task_id=download_dataset_task, execution_date=20090101T000000, start_date=20220502T165008, end_date=20220502T165010
[2022-05-02 16:50:10,177] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-05-02 16:50:10,614] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
