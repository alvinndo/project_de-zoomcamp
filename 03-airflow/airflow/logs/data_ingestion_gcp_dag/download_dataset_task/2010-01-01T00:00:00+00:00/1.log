[2022-04-25 05:59:24,766] {taskinstance.py:1043} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2010-01-01T00:00:00+00:00 [queued]>
[2022-04-25 05:59:24,815] {taskinstance.py:1043} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2010-01-01T00:00:00+00:00 [queued]>
[2022-04-25 05:59:24,817] {taskinstance.py:1249} INFO - 
--------------------------------------------------------------------------------
[2022-04-25 05:59:24,818] {taskinstance.py:1250} INFO - Starting attempt 1 of 2
[2022-04-25 05:59:24,819] {taskinstance.py:1251} INFO - 
--------------------------------------------------------------------------------
[2022-04-25 05:59:24,869] {taskinstance.py:1270} INFO - Executing <Task(BashOperator): download_dataset_task> on 2010-01-01 00:00:00+00:00
[2022-04-25 05:59:24,876] {standard_task_runner.py:52} INFO - Started process 936 to run task
[2022-04-25 05:59:24,896] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcp_dag', 'download_dataset_task', 'scheduled__2010-01-01T00:00:00+00:00', '--job-id', '299', '--raw', '--subdir', 'DAGS_FOLDER/ingest_to_gcs_dag.py', '--cfg-path', '/tmp/tmpntb45rk_', '--error-file', '/tmp/tmps9s00ayr']
[2022-04-25 05:59:24,902] {standard_task_runner.py:80} INFO - Job 299: Subtask download_dataset_task
[2022-04-25 05:59:25,362] {logging_mixin.py:109} INFO - Running <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2010-01-01T00:00:00+00:00 [running]> on host d74937eb3452
[2022-04-25 05:59:25,632] {logging_mixin.py:109} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:156 AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
[2022-04-25 05:59:25,826] {taskinstance.py:1448} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=data_ingestion_gcp_dag
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2010-01-01T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2010-01-01T00:00:00+00:00
[2022-04-25 05:59:25,831] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-04-25 05:59:25,833] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://www.bls.gov/lau/laucnty10.xlsx > /opt/***//laucnty10.xlsx']
[2022-04-25 05:59:25,853] {subprocess.py:85} INFO - Output:
[2022-04-25 05:59:26,234] {subprocess.py:93} INFO - Command exited with return code 0
[2022-04-25 05:59:26,422] {taskinstance.py:1288} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcp_dag, task_id=download_dataset_task, execution_date=20100101T000000, start_date=20220425T055924, end_date=20220425T055926
[2022-04-25 05:59:26,508] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-04-25 05:59:26,713] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-04-28 06:09:02,170] {taskinstance.py:1043} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2010-01-01T00:00:00+00:00 [queued]>
[2022-04-28 06:09:02,212] {taskinstance.py:1043} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2010-01-01T00:00:00+00:00 [queued]>
[2022-04-28 06:09:02,214] {taskinstance.py:1249} INFO - 
--------------------------------------------------------------------------------
[2022-04-28 06:09:02,215] {taskinstance.py:1250} INFO - Starting attempt 1 of 2
[2022-04-28 06:09:02,217] {taskinstance.py:1251} INFO - 
--------------------------------------------------------------------------------
[2022-04-28 06:09:02,260] {taskinstance.py:1270} INFO - Executing <Task(BashOperator): download_dataset_task> on 2010-01-01 00:00:00+00:00
[2022-04-28 06:09:02,271] {standard_task_runner.py:52} INFO - Started process 2453 to run task
[2022-04-28 06:09:02,279] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcp_dag', 'download_dataset_task', 'scheduled__2010-01-01T00:00:00+00:00', '--job-id', '567', '--raw', '--subdir', 'DAGS_FOLDER/ingest_to_gcs_dag.py', '--cfg-path', '/tmp/tmp3vm0da5p', '--error-file', '/tmp/tmpqb02dc6f']
[2022-04-28 06:09:02,283] {standard_task_runner.py:80} INFO - Job 567: Subtask download_dataset_task
[2022-04-28 06:09:02,645] {logging_mixin.py:109} INFO - Running <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2010-01-01T00:00:00+00:00 [running]> on host d4721d223bdd
[2022-04-28 06:09:02,871] {logging_mixin.py:109} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:156 AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
[2022-04-28 06:09:03,055] {taskinstance.py:1448} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=data_ingestion_gcp_dag
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2010-01-01T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2010-01-01T00:00:00+00:00
[2022-04-28 06:09:03,059] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-04-28 06:09:03,061] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://www.bls.gov/lau/laucnty10.xlsx > /opt/***/laucnty10.xlsx']
[2022-04-28 06:09:03,075] {subprocess.py:85} INFO - Output:
[2022-04-28 06:09:03,857] {subprocess.py:93} INFO - Command exited with return code 0
[2022-04-28 06:09:04,056] {taskinstance.py:1288} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcp_dag, task_id=download_dataset_task, execution_date=20100101T000000, start_date=20220428T060902, end_date=20220428T060904
[2022-04-28 06:09:04,107] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-04-28 06:09:04,352] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-04-29 02:38:03,239] {taskinstance.py:1043} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2010-01-01T00:00:00+00:00 [queued]>
[2022-04-29 02:38:03,285] {taskinstance.py:1043} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2010-01-01T00:00:00+00:00 [queued]>
[2022-04-29 02:38:03,287] {taskinstance.py:1249} INFO - 
--------------------------------------------------------------------------------
[2022-04-29 02:38:03,290] {taskinstance.py:1250} INFO - Starting attempt 1 of 2
[2022-04-29 02:38:03,291] {taskinstance.py:1251} INFO - 
--------------------------------------------------------------------------------
[2022-04-29 02:38:03,345] {taskinstance.py:1270} INFO - Executing <Task(BashOperator): download_dataset_task> on 2010-01-01 00:00:00+00:00
[2022-04-29 02:38:03,358] {standard_task_runner.py:52} INFO - Started process 5896 to run task
[2022-04-29 02:38:03,376] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcp_dag', 'download_dataset_task', 'scheduled__2010-01-01T00:00:00+00:00', '--job-id', '740', '--raw', '--subdir', 'DAGS_FOLDER/ingest_to_gcs_dag.py', '--cfg-path', '/tmp/tmp4hd6xu91', '--error-file', '/tmp/tmpaz_ep69j']
[2022-04-29 02:38:03,379] {standard_task_runner.py:80} INFO - Job 740: Subtask download_dataset_task
[2022-04-29 02:38:03,806] {logging_mixin.py:109} INFO - Running <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2010-01-01T00:00:00+00:00 [running]> on host 6fd0ba274d58
[2022-04-29 02:38:04,101] {logging_mixin.py:109} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:156 AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
[2022-04-29 02:38:04,294] {taskinstance.py:1448} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=data_ingestion_gcp_dag
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2010-01-01T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2010-01-01T00:00:00+00:00
[2022-04-29 02:38:04,300] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-04-29 02:38:04,304] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://www.bls.gov/lau/laucnty10.xlsx > /opt/***/laucnty10.xlsx']
[2022-04-29 02:38:04,325] {subprocess.py:85} INFO - Output:
[2022-04-29 02:38:04,998] {subprocess.py:93} INFO - Command exited with return code 0
[2022-04-29 02:38:05,424] {taskinstance.py:1288} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcp_dag, task_id=download_dataset_task, execution_date=20100101T000000, start_date=20220429T023803, end_date=20220429T023805
[2022-04-29 02:38:05,512] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-04-29 02:38:06,214] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-05-02 07:56:54,414] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2010-01-01T00:00:00+00:00 [queued]>
[2022-05-02 07:56:54,460] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2010-01-01T00:00:00+00:00 [queued]>
[2022-05-02 07:56:54,462] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-05-02 07:56:54,464] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-05-02 07:56:54,466] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-05-02 07:56:54,514] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2010-01-01 00:00:00+00:00
[2022-05-02 07:56:54,524] {standard_task_runner.py:52} INFO - Started process 9750 to run task
[2022-05-02 07:56:54,538] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcp_dag', 'download_dataset_task', 'scheduled__2010-01-01T00:00:00+00:00', '--job-id', '883', '--raw', '--subdir', 'DAGS_FOLDER/ingest_to_gcs_dag.py', '--cfg-path', '/tmp/tmpfm9nsq02', '--error-file', '/tmp/tmpq9ddd859']
[2022-05-02 07:56:54,543] {standard_task_runner.py:77} INFO - Job 883: Subtask download_dataset_task
[2022-05-02 07:56:54,935] {logging_mixin.py:109} INFO - Running <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2010-01-01T00:00:00+00:00 [running]> on host ae42322ae538
[2022-05-02 07:56:55,333] {logging_mixin.py:109} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152 AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
[2022-05-02 07:56:55,576] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=data_ingestion_gcp_dag
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2010-01-01T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2010-01-01T00:00:00+00:00
[2022-05-02 07:56:55,581] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-05-02 07:56:55,587] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://www.bls.gov/lau/laucnty10.xlsx > /opt/***/laucnty10.xlsx']
[2022-05-02 07:56:55,634] {subprocess.py:85} INFO - Output:
[2022-05-02 07:56:56,128] {subprocess.py:93} INFO - Command exited with return code 0
[2022-05-02 07:56:56,448] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcp_dag, task_id=download_dataset_task, execution_date=20100101T000000, start_date=20220502T075654, end_date=20220502T075656
[2022-05-02 07:56:56,510] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-05-02 07:56:57,260] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-05-02 09:18:34,918] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2010-01-01T00:00:00+00:00 [queued]>
[2022-05-02 09:18:34,964] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2010-01-01T00:00:00+00:00 [queued]>
[2022-05-02 09:18:34,966] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-05-02 09:18:34,967] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-05-02 09:18:34,968] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-05-02 09:18:35,015] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2010-01-01 00:00:00+00:00
[2022-05-02 09:18:35,025] {standard_task_runner.py:52} INFO - Started process 2917 to run task
[2022-05-02 09:18:35,040] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcp_dag', 'download_dataset_task', 'scheduled__2010-01-01T00:00:00+00:00', '--job-id', '998', '--raw', '--subdir', 'DAGS_FOLDER/ingest_to_gcs_dag.py', '--cfg-path', '/tmp/tmprsf564q0', '--error-file', '/tmp/tmp2avm8u62']
[2022-05-02 09:18:35,043] {standard_task_runner.py:77} INFO - Job 998: Subtask download_dataset_task
[2022-05-02 09:18:35,416] {logging_mixin.py:109} INFO - Running <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2010-01-01T00:00:00+00:00 [running]> on host 98c324cf1bb6
[2022-05-02 09:18:35,673] {logging_mixin.py:109} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152 AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
[2022-05-02 09:18:35,853] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=data_ingestion_gcp_dag
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2010-01-01T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2010-01-01T00:00:00+00:00
[2022-05-02 09:18:35,857] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-05-02 09:18:35,859] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://www.bls.gov/lau/laucnty10.xlsx > /opt/***/laucnty10.xlsx']
[2022-05-02 09:18:35,897] {subprocess.py:85} INFO - Output:
[2022-05-02 09:18:36,256] {subprocess.py:93} INFO - Command exited with return code 0
[2022-05-02 09:18:36,515] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcp_dag, task_id=download_dataset_task, execution_date=20100101T000000, start_date=20220502T091834, end_date=20220502T091836
[2022-05-02 09:18:36,581] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-05-02 09:18:37,347] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-05-02 15:59:41,174] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2010-01-01T00:00:00+00:00 [queued]>
[2022-05-02 15:59:41,236] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2010-01-01T00:00:00+00:00 [queued]>
[2022-05-02 15:59:41,238] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-05-02 15:59:41,239] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-05-02 15:59:41,241] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-05-02 15:59:41,297] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2010-01-01 00:00:00+00:00
[2022-05-02 15:59:41,307] {standard_task_runner.py:52} INFO - Started process 2061 to run task
[2022-05-02 15:59:41,330] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcp_dag', 'download_dataset_task', 'scheduled__2010-01-01T00:00:00+00:00', '--job-id', '1099', '--raw', '--subdir', 'DAGS_FOLDER/ingest_to_gcs_dag.py', '--cfg-path', '/tmp/tmpf1ga8w2m', '--error-file', '/tmp/tmpe9vpbfrx']
[2022-05-02 15:59:41,334] {standard_task_runner.py:77} INFO - Job 1099: Subtask download_dataset_task
[2022-05-02 15:59:41,733] {logging_mixin.py:109} INFO - Running <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2010-01-01T00:00:00+00:00 [running]> on host 9f5021834e17
[2022-05-02 15:59:42,016] {logging_mixin.py:109} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152 AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
[2022-05-02 15:59:42,217] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=data_ingestion_gcp_dag
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2010-01-01T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2010-01-01T00:00:00+00:00
[2022-05-02 15:59:42,222] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-05-02 15:59:42,224] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://www.bls.gov/lau/laucnty10.xlsx > /opt/***/laucnty10.xlsx']
[2022-05-02 15:59:42,246] {subprocess.py:85} INFO - Output:
[2022-05-02 15:59:42,832] {subprocess.py:93} INFO - Command exited with return code 0
[2022-05-02 15:59:43,272] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcp_dag, task_id=download_dataset_task, execution_date=20100101T000000, start_date=20220502T155941, end_date=20220502T155943
[2022-05-02 15:59:43,497] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-05-02 15:59:43,873] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-05-02 16:34:40,016] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2010-01-01T00:00:00+00:00 [queued]>
[2022-05-02 16:34:40,074] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2010-01-01T00:00:00+00:00 [queued]>
[2022-05-02 16:34:40,077] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-05-02 16:34:40,078] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-05-02 16:34:40,082] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-05-02 16:34:40,148] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2010-01-01 00:00:00+00:00
[2022-05-02 16:34:40,160] {standard_task_runner.py:52} INFO - Started process 6632 to run task
[2022-05-02 16:34:40,172] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcp_dag', 'download_dataset_task', 'scheduled__2010-01-01T00:00:00+00:00', '--job-id', '1206', '--raw', '--subdir', 'DAGS_FOLDER/ingest_to_gcs_dag.py', '--cfg-path', '/tmp/tmprjw9rkd2', '--error-file', '/tmp/tmpjs2ihxee']
[2022-05-02 16:34:40,175] {standard_task_runner.py:77} INFO - Job 1206: Subtask download_dataset_task
[2022-05-02 16:34:40,825] {logging_mixin.py:109} INFO - Running <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2010-01-01T00:00:00+00:00 [running]> on host 9f5021834e17
[2022-05-02 16:34:41,488] {logging_mixin.py:109} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152 AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
[2022-05-02 16:34:41,817] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=data_ingestion_gcp_dag
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2010-01-01T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2010-01-01T00:00:00+00:00
[2022-05-02 16:34:41,826] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-05-02 16:34:41,844] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://www.bls.gov/lau/laucnty10.xlsx > /opt/***/laucnty10.xlsx']
[2022-05-02 16:34:41,886] {subprocess.py:85} INFO - Output:
[2022-05-02 16:34:42,712] {subprocess.py:93} INFO - Command exited with return code 0
[2022-05-02 16:34:42,992] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcp_dag, task_id=download_dataset_task, execution_date=20100101T000000, start_date=20220502T163440, end_date=20220502T163442
[2022-05-02 16:34:43,120] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-05-02 16:34:43,733] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-05-02 16:50:34,882] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2010-01-01T00:00:00+00:00 [queued]>
[2022-05-02 16:50:34,937] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2010-01-01T00:00:00+00:00 [queued]>
[2022-05-02 16:50:34,939] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-05-02 16:50:34,941] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-05-02 16:50:34,943] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-05-02 16:50:35,002] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2010-01-01 00:00:00+00:00
[2022-05-02 16:50:35,014] {standard_task_runner.py:52} INFO - Started process 9543 to run task
[2022-05-02 16:50:35,030] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcp_dag', 'download_dataset_task', 'scheduled__2010-01-01T00:00:00+00:00', '--job-id', '1314', '--raw', '--subdir', 'DAGS_FOLDER/ingest_to_gcs_dag.py', '--cfg-path', '/tmp/tmpd9frj6ks', '--error-file', '/tmp/tmpdh7ufvkm']
[2022-05-02 16:50:35,035] {standard_task_runner.py:77} INFO - Job 1314: Subtask download_dataset_task
[2022-05-02 16:50:35,521] {logging_mixin.py:109} INFO - Running <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2010-01-01T00:00:00+00:00 [running]> on host 9f5021834e17
[2022-05-02 16:50:35,809] {logging_mixin.py:109} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152 AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
[2022-05-02 16:50:36,001] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=data_ingestion_gcp_dag
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2010-01-01T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2010-01-01T00:00:00+00:00
[2022-05-02 16:50:36,006] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-05-02 16:50:36,009] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://www.bls.gov/lau/laucnty10.xlsx > /opt/***/laucnty10.xlsx']
[2022-05-02 16:50:36,032] {subprocess.py:85} INFO - Output:
[2022-05-02 16:50:36,941] {subprocess.py:93} INFO - Command exited with return code 0
[2022-05-02 16:50:37,238] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcp_dag, task_id=download_dataset_task, execution_date=20100101T000000, start_date=20220502T165034, end_date=20220502T165037
[2022-05-02 16:50:37,302] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-05-02 16:50:37,597] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
