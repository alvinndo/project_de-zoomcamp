[2022-04-25 05:59:45,322] {taskinstance.py:1043} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2019-01-01T00:00:00+00:00 [queued]>
[2022-04-25 05:59:45,373] {taskinstance.py:1043} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2019-01-01T00:00:00+00:00 [queued]>
[2022-04-25 05:59:45,374] {taskinstance.py:1249} INFO - 
--------------------------------------------------------------------------------
[2022-04-25 05:59:45,376] {taskinstance.py:1250} INFO - Starting attempt 1 of 2
[2022-04-25 05:59:45,378] {taskinstance.py:1251} INFO - 
--------------------------------------------------------------------------------
[2022-04-25 05:59:45,431] {taskinstance.py:1270} INFO - Executing <Task(BashOperator): download_dataset_task> on 2019-01-01 00:00:00+00:00
[2022-04-25 05:59:45,440] {standard_task_runner.py:52} INFO - Started process 1087 to run task
[2022-04-25 05:59:45,447] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcp_dag', 'download_dataset_task', 'scheduled__2019-01-01T00:00:00+00:00', '--job-id', '308', '--raw', '--subdir', 'DAGS_FOLDER/ingest_to_gcs_dag.py', '--cfg-path', '/tmp/tmpgdl14n3c', '--error-file', '/tmp/tmpegnk3rt8']
[2022-04-25 05:59:45,450] {standard_task_runner.py:80} INFO - Job 308: Subtask download_dataset_task
[2022-04-25 05:59:45,868] {logging_mixin.py:109} INFO - Running <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2019-01-01T00:00:00+00:00 [running]> on host d74937eb3452
[2022-04-25 05:59:46,117] {logging_mixin.py:109} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:156 AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
[2022-04-25 05:59:46,307] {taskinstance.py:1448} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=data_ingestion_gcp_dag
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2019-01-01T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-01-01T00:00:00+00:00
[2022-04-25 05:59:46,312] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-04-25 05:59:46,319] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://www.bls.gov/lau/laucnty19.xlsx > /opt/***//laucnty19.xlsx']
[2022-04-25 05:59:46,338] {subprocess.py:85} INFO - Output:
[2022-04-25 05:59:46,732] {subprocess.py:93} INFO - Command exited with return code 0
[2022-04-25 05:59:46,930] {taskinstance.py:1288} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcp_dag, task_id=download_dataset_task, execution_date=20190101T000000, start_date=20220425T055945, end_date=20220425T055946
[2022-04-25 05:59:46,994] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-04-25 05:59:47,197] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-04-28 06:13:11,159] {taskinstance.py:1043} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2019-01-01T00:00:00+00:00 [queued]>
[2022-04-28 06:13:11,205] {taskinstance.py:1043} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2019-01-01T00:00:00+00:00 [queued]>
[2022-04-28 06:13:11,206] {taskinstance.py:1249} INFO - 
--------------------------------------------------------------------------------
[2022-04-28 06:13:11,207] {taskinstance.py:1250} INFO - Starting attempt 1 of 2
[2022-04-28 06:13:11,209] {taskinstance.py:1251} INFO - 
--------------------------------------------------------------------------------
[2022-04-28 06:13:11,257] {taskinstance.py:1270} INFO - Executing <Task(BashOperator): download_dataset_task> on 2019-01-01 00:00:00+00:00
[2022-04-28 06:13:11,266] {standard_task_runner.py:52} INFO - Started process 3254 to run task
[2022-04-28 06:13:11,274] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcp_dag', 'download_dataset_task', 'scheduled__2019-01-01T00:00:00+00:00', '--job-id', '612', '--raw', '--subdir', 'DAGS_FOLDER/ingest_to_gcs_dag.py', '--cfg-path', '/tmp/tmpvg2o3pgu', '--error-file', '/tmp/tmpslz1tvgg']
[2022-04-28 06:13:11,277] {standard_task_runner.py:80} INFO - Job 612: Subtask download_dataset_task
[2022-04-28 06:13:11,646] {logging_mixin.py:109} INFO - Running <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2019-01-01T00:00:00+00:00 [running]> on host d4721d223bdd
[2022-04-28 06:13:11,897] {logging_mixin.py:109} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:156 AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
[2022-04-28 06:13:12,083] {taskinstance.py:1448} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=data_ingestion_gcp_dag
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2019-01-01T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-01-01T00:00:00+00:00
[2022-04-28 06:13:12,087] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-04-28 06:13:12,090] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://www.bls.gov/lau/laucnty19.xlsx > /opt/***/laucnty19.xlsx']
[2022-04-28 06:13:12,107] {subprocess.py:85} INFO - Output:
[2022-04-28 06:13:12,919] {subprocess.py:93} INFO - Command exited with return code 0
[2022-04-28 06:13:13,194] {taskinstance.py:1288} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcp_dag, task_id=download_dataset_task, execution_date=20190101T000000, start_date=20220428T061311, end_date=20220428T061313
[2022-04-28 06:13:13,263] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-04-28 06:13:13,536] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-04-29 02:40:08,637] {taskinstance.py:1043} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2019-01-01T00:00:00+00:00 [queued]>
[2022-04-29 02:40:08,688] {taskinstance.py:1043} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2019-01-01T00:00:00+00:00 [queued]>
[2022-04-29 02:40:08,690] {taskinstance.py:1249} INFO - 
--------------------------------------------------------------------------------
[2022-04-29 02:40:08,692] {taskinstance.py:1250} INFO - Starting attempt 1 of 2
[2022-04-29 02:40:08,693] {taskinstance.py:1251} INFO - 
--------------------------------------------------------------------------------
[2022-04-29 02:40:08,743] {taskinstance.py:1270} INFO - Executing <Task(BashOperator): download_dataset_task> on 2019-01-01 00:00:00+00:00
[2022-04-29 02:40:08,755] {standard_task_runner.py:52} INFO - Started process 6460 to run task
[2022-04-29 02:40:08,770] {standard_task_runner.py:79} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcp_dag', 'download_dataset_task', 'scheduled__2019-01-01T00:00:00+00:00', '--job-id', '776', '--raw', '--subdir', 'DAGS_FOLDER/ingest_to_gcs_dag.py', '--cfg-path', '/tmp/tmpi3vnto1o', '--error-file', '/tmp/tmp16q3yw95']
[2022-04-29 02:40:08,776] {standard_task_runner.py:80} INFO - Job 776: Subtask download_dataset_task
[2022-04-29 02:40:09,197] {logging_mixin.py:109} INFO - Running <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2019-01-01T00:00:00+00:00 [running]> on host 6fd0ba274d58
[2022-04-29 02:40:09,658] {logging_mixin.py:109} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:156 AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
[2022-04-29 02:40:09,911] {taskinstance.py:1448} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=data_ingestion_gcp_dag
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2019-01-01T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-01-01T00:00:00+00:00
[2022-04-29 02:40:09,925] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-04-29 02:40:09,931] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://www.bls.gov/lau/laucnty19.xlsx > /opt/***/laucnty19.xlsx']
[2022-04-29 02:40:09,970] {subprocess.py:85} INFO - Output:
[2022-04-29 02:40:10,824] {subprocess.py:93} INFO - Command exited with return code 0
[2022-04-29 02:40:11,223] {taskinstance.py:1288} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcp_dag, task_id=download_dataset_task, execution_date=20190101T000000, start_date=20220429T024008, end_date=20220429T024011
[2022-04-29 02:40:11,415] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-04-29 02:40:12,306] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-05-02 07:58:42,826] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2019-01-01T00:00:00+00:00 [queued]>
[2022-05-02 07:58:42,876] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2019-01-01T00:00:00+00:00 [queued]>
[2022-05-02 07:58:42,878] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-05-02 07:58:42,879] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-05-02 07:58:42,881] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-05-02 07:58:42,934] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2019-01-01 00:00:00+00:00
[2022-05-02 07:58:42,944] {standard_task_runner.py:52} INFO - Started process 10218 to run task
[2022-05-02 07:58:42,959] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcp_dag', 'download_dataset_task', 'scheduled__2019-01-01T00:00:00+00:00', '--job-id', '910', '--raw', '--subdir', 'DAGS_FOLDER/ingest_to_gcs_dag.py', '--cfg-path', '/tmp/tmpa1jr9qz1', '--error-file', '/tmp/tmpj4yyve14']
[2022-05-02 07:58:42,962] {standard_task_runner.py:77} INFO - Job 910: Subtask download_dataset_task
[2022-05-02 07:58:43,350] {logging_mixin.py:109} INFO - Running <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2019-01-01T00:00:00+00:00 [running]> on host ae42322ae538
[2022-05-02 07:58:43,729] {logging_mixin.py:109} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152 AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
[2022-05-02 07:58:43,935] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=data_ingestion_gcp_dag
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2019-01-01T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-01-01T00:00:00+00:00
[2022-05-02 07:58:43,940] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-05-02 07:58:43,942] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://www.bls.gov/lau/laucnty19.xlsx > /opt/***/laucnty19.xlsx']
[2022-05-02 07:58:43,971] {subprocess.py:85} INFO - Output:
[2022-05-02 07:58:44,384] {subprocess.py:93} INFO - Command exited with return code 0
[2022-05-02 07:58:44,600] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcp_dag, task_id=download_dataset_task, execution_date=20190101T000000, start_date=20220502T075842, end_date=20220502T075844
[2022-05-02 07:58:44,689] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-05-02 07:58:44,959] {local_task_job.py:264} INFO - 1 downstream tasks scheduled from follow-on schedule check
[2022-05-02 09:20:09,672] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2019-01-01T00:00:00+00:00 [queued]>
[2022-05-02 09:20:09,729] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2019-01-01T00:00:00+00:00 [queued]>
[2022-05-02 09:20:09,731] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-05-02 09:20:09,732] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-05-02 09:20:09,734] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-05-02 09:20:09,781] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2019-01-01 00:00:00+00:00
[2022-05-02 09:20:09,791] {standard_task_runner.py:52} INFO - Started process 3386 to run task
[2022-05-02 09:20:09,818] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcp_dag', 'download_dataset_task', 'scheduled__2019-01-01T00:00:00+00:00', '--job-id', '1025', '--raw', '--subdir', 'DAGS_FOLDER/ingest_to_gcs_dag.py', '--cfg-path', '/tmp/tmpbaeiwdmq', '--error-file', '/tmp/tmporfpijce']
[2022-05-02 09:20:09,831] {standard_task_runner.py:77} INFO - Job 1025: Subtask download_dataset_task
[2022-05-02 09:20:10,240] {logging_mixin.py:109} INFO - Running <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2019-01-01T00:00:00+00:00 [running]> on host 98c324cf1bb6
[2022-05-02 09:20:10,528] {logging_mixin.py:109} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152 AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
[2022-05-02 09:20:10,727] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=data_ingestion_gcp_dag
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2019-01-01T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-01-01T00:00:00+00:00
[2022-05-02 09:20:10,732] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-05-02 09:20:10,734] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://www.bls.gov/lau/laucnty19.xlsx > /opt/***/laucnty19.xlsx']
[2022-05-02 09:20:10,752] {subprocess.py:85} INFO - Output:
[2022-05-02 09:20:11,144] {subprocess.py:93} INFO - Command exited with return code 0
[2022-05-02 09:20:11,344] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcp_dag, task_id=download_dataset_task, execution_date=20190101T000000, start_date=20220502T092009, end_date=20220502T092011
[2022-05-02 09:20:11,405] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-05-02 09:20:12,134] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-05-02 16:01:12,387] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2019-01-01T00:00:00+00:00 [queued]>
[2022-05-02 16:01:12,436] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2019-01-01T00:00:00+00:00 [queued]>
[2022-05-02 16:01:12,439] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-05-02 16:01:12,443] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-05-02 16:01:12,448] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-05-02 16:01:12,629] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2019-01-01 00:00:00+00:00
[2022-05-02 16:01:12,646] {standard_task_runner.py:52} INFO - Started process 2513 to run task
[2022-05-02 16:01:12,663] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcp_dag', 'download_dataset_task', 'scheduled__2019-01-01T00:00:00+00:00', '--job-id', '1126', '--raw', '--subdir', 'DAGS_FOLDER/ingest_to_gcs_dag.py', '--cfg-path', '/tmp/tmpd8o7ddo0', '--error-file', '/tmp/tmpzh2stl4j']
[2022-05-02 16:01:12,667] {standard_task_runner.py:77} INFO - Job 1126: Subtask download_dataset_task
[2022-05-02 16:01:13,284] {logging_mixin.py:109} INFO - Running <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2019-01-01T00:00:00+00:00 [running]> on host 9f5021834e17
[2022-05-02 16:01:13,655] {logging_mixin.py:109} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152 AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
[2022-05-02 16:01:13,844] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=data_ingestion_gcp_dag
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2019-01-01T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-01-01T00:00:00+00:00
[2022-05-02 16:01:13,850] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-05-02 16:01:13,852] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://www.bls.gov/lau/laucnty19.xlsx > /opt/***/laucnty19.xlsx']
[2022-05-02 16:01:13,868] {subprocess.py:85} INFO - Output:
[2022-05-02 16:01:14,630] {subprocess.py:93} INFO - Command exited with return code 0
[2022-05-02 16:01:14,962] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcp_dag, task_id=download_dataset_task, execution_date=20190101T000000, start_date=20220502T160112, end_date=20220502T160114
[2022-05-02 16:01:15,093] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-05-02 16:01:15,770] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-05-02 16:36:46,039] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2019-01-01T00:00:00+00:00 [queued]>
[2022-05-02 16:36:46,088] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2019-01-01T00:00:00+00:00 [queued]>
[2022-05-02 16:36:46,090] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-05-02 16:36:46,092] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-05-02 16:36:46,093] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-05-02 16:36:46,142] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2019-01-01 00:00:00+00:00
[2022-05-02 16:36:46,153] {standard_task_runner.py:52} INFO - Started process 7149 to run task
[2022-05-02 16:36:46,161] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcp_dag', 'download_dataset_task', 'scheduled__2019-01-01T00:00:00+00:00', '--job-id', '1235', '--raw', '--subdir', 'DAGS_FOLDER/ingest_to_gcs_dag.py', '--cfg-path', '/tmp/tmp8j2lify0', '--error-file', '/tmp/tmpoyvndtgz']
[2022-05-02 16:36:46,165] {standard_task_runner.py:77} INFO - Job 1235: Subtask download_dataset_task
[2022-05-02 16:36:46,570] {logging_mixin.py:109} INFO - Running <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2019-01-01T00:00:00+00:00 [running]> on host 9f5021834e17
[2022-05-02 16:36:46,907] {logging_mixin.py:109} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152 AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
[2022-05-02 16:36:47,136] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=data_ingestion_gcp_dag
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2019-01-01T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-01-01T00:00:00+00:00
[2022-05-02 16:36:47,143] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-05-02 16:36:47,146] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://www.bls.gov/lau/laucnty19.xlsx > /opt/***/laucnty19.xlsx']
[2022-05-02 16:36:47,174] {subprocess.py:85} INFO - Output:
[2022-05-02 16:36:47,811] {subprocess.py:93} INFO - Command exited with return code 0
[2022-05-02 16:36:48,124] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcp_dag, task_id=download_dataset_task, execution_date=20190101T000000, start_date=20220502T163646, end_date=20220502T163648
[2022-05-02 16:36:48,237] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-05-02 16:36:48,581] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
[2022-05-02 16:52:26,084] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2019-01-01T00:00:00+00:00 [queued]>
[2022-05-02 16:52:26,127] {taskinstance.py:1032} INFO - Dependencies all met for <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2019-01-01T00:00:00+00:00 [queued]>
[2022-05-02 16:52:26,129] {taskinstance.py:1238} INFO - 
--------------------------------------------------------------------------------
[2022-05-02 16:52:26,130] {taskinstance.py:1239} INFO - Starting attempt 1 of 2
[2022-05-02 16:52:26,136] {taskinstance.py:1240} INFO - 
--------------------------------------------------------------------------------
[2022-05-02 16:52:26,179] {taskinstance.py:1259} INFO - Executing <Task(BashOperator): download_dataset_task> on 2019-01-01 00:00:00+00:00
[2022-05-02 16:52:26,189] {standard_task_runner.py:52} INFO - Started process 10019 to run task
[2022-05-02 16:52:26,197] {standard_task_runner.py:76} INFO - Running: ['***', 'tasks', 'run', 'data_ingestion_gcp_dag', 'download_dataset_task', 'scheduled__2019-01-01T00:00:00+00:00', '--job-id', '1341', '--raw', '--subdir', 'DAGS_FOLDER/ingest_to_gcs_dag.py', '--cfg-path', '/tmp/tmpjxhgrxk1', '--error-file', '/tmp/tmp72hey0vk']
[2022-05-02 16:52:26,200] {standard_task_runner.py:77} INFO - Job 1341: Subtask download_dataset_task
[2022-05-02 16:52:26,583] {logging_mixin.py:109} INFO - Running <TaskInstance: data_ingestion_gcp_dag.download_dataset_task scheduled__2019-01-01T00:00:00+00:00 [running]> on host 9f5021834e17
[2022-05-02 16:52:26,846] {logging_mixin.py:109} WARNING - /home/***/.local/lib/python3.7/site-packages/***/utils/context.py:152 AirflowContextDeprecationWarning: Accessing 'execution_date' from the template is deprecated and will be removed in a future version. Please use 'data_interval_start' or 'logical_date' instead.
[2022-05-02 16:52:27,034] {taskinstance.py:1426} INFO - Exporting the following env vars:
AIRFLOW_CTX_DAG_OWNER=***
AIRFLOW_CTX_DAG_ID=data_ingestion_gcp_dag
AIRFLOW_CTX_TASK_ID=download_dataset_task
AIRFLOW_CTX_EXECUTION_DATE=2019-01-01T00:00:00+00:00
AIRFLOW_CTX_DAG_RUN_ID=scheduled__2019-01-01T00:00:00+00:00
[2022-05-02 16:52:27,039] {subprocess.py:62} INFO - Tmp dir root location: 
 /tmp
[2022-05-02 16:52:27,041] {subprocess.py:74} INFO - Running command: ['bash', '-c', 'curl -sSLf https://www.bls.gov/lau/laucnty19.xlsx > /opt/***/laucnty19.xlsx']
[2022-05-02 16:52:27,078] {subprocess.py:85} INFO - Output:
[2022-05-02 16:52:27,559] {subprocess.py:93} INFO - Command exited with return code 0
[2022-05-02 16:52:27,761] {taskinstance.py:1277} INFO - Marking task as SUCCESS. dag_id=data_ingestion_gcp_dag, task_id=download_dataset_task, execution_date=20190101T000000, start_date=20220502T165226, end_date=20220502T165227
[2022-05-02 16:52:27,816] {local_task_job.py:154} INFO - Task exited with return code 0
[2022-05-02 16:52:28,288] {local_task_job.py:264} INFO - 0 downstream tasks scheduled from follow-on schedule check
